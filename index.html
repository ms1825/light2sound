<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Optical Vocoder Receiver</title>
    <style>
        body { 
            margin: 0; 
            background: #000; 
            color: #0f0; 
            font-family: 'Courier New', monospace; 
            overflow: hidden; 
        }
        /* Video fills the screen */
        video { 
            position: absolute; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%; 
            object-fit: cover; 
            filter: contrast(1.2) brightness(1.1); /* Slight boost to help detection */
        }
        
        /* The Overlay Canvas (for red boxes) sits on top */
        #overlay { 
            position: absolute; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%; 
            pointer-events: none; 
        }
        
        /* UI Elements */
        #ui { 
            position: absolute; 
            top: 10px; 
            left: 10px; 
            z-index: 10; 
            background: rgba(0,0,0,0.6); 
            padding: 5px 10px; 
            border: 1px solid #0f0;
            pointer-events: none; 
        }
        #fps { font-weight: bold; font-size: 16px; }
        #status { font-size: 12px; color: #aaa; margin-top: 2px; }

        /* Start Button */
        #startBtn { 
            position: absolute; 
            bottom: 50px; 
            left: 50%; 
            transform: translateX(-50%); 
            padding: 20px 40px; 
            font-size: 20px; 
            font-weight: bold; 
            background: #0f0; 
            color: #000;
            border: none; 
            cursor: pointer; 
            z-index: 20; 
            box-shadow: 0 0 15px #0f0;
        }
    </style>
</head>
<body>

    <video id="video" autoplay playsinline muted></video>
    
    <canvas id="overlay"></canvas>
    
    <div id="ui">
        <div id="fps">FPS: 0</div>
        <div id="status">Ready to initialize</div>
    </div>

    <button id="startBtn">START RECEIVER</button>

    <canvas id="proc" style="display:none;"></canvas>

        <script>
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const overlayCtx = overlay.getContext('2d');
        const proc = document.getElementById('proc');
        const ctx = proc.getContext('2d', { willReadFrequently: true });
        const fpsDisp = document.getElementById('fps');
        const statusDisp = document.getElementById('status');
        
        let audioCtx;
        const synths = [];
        let isRunning = false;

        // --- NEW FREQUENCIES (Phone Speaker Friendly) ---
        // 440Hz (A4), 554Hz (C#5), 659Hz (E5) -> A Major Chord
        // These are high enough for any phone speaker to play clearly.
        const tonalFreqs = [440, 554, 659]; 

        let lastTime = 0;
        let frames = 0;

        function createNoiseBuffer(ctx) {
            const bufferSize = ctx.sampleRate * 2; 
            const buffer = ctx.createBuffer(1, bufferSize, ctx.sampleRate);
            const data = buffer.getChannelData(0);
            for (let i = 0; i < bufferSize; i++) {
                data[i] = Math.random() * 2 - 1;
            }
            return buffer;
        }

        document.getElementById('startBtn').addEventListener('click', async () => {
            document.getElementById('startBtn').style.display = 'none';
            statusDisp.innerText = "Accessing Camera...";

            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const noiseBuffer = createNoiseBuffer(audioCtx);

            for(let i=0; i<5; i++) {
                const gain = audioCtx.createGain();
                gain.gain.value = 0;
                gain.connect(audioCtx.destination);

                let node;

                if (i < 3) {
                    // CHANNELS 0-2: Square Wave (8-Bit Sound)
                    // Much louder and clearer on phone speakers
                    node = audioCtx.createOscillator();
                    node.type = 'square'; 
                    node.frequency.value = tonalFreqs[i];
                    node.start();
                } else {
                    // CHANNELS 3-4: White Noise
                    node = audioCtx.createBufferSource();
                    node.buffer = noiseBuffer;
                    node.loop = true;
                    // Lowered playback rate for a "crunchier" static sound
                    node.playbackRate.value = i === 3 ? 0.5 : 1.0; 
                    node.start();
                }

                node.connect(gain);
                synths.push({ node, gain });
            }

            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'environment', width: { ideal: 1280 }, frameRate: { ideal: 60, min: 30 } }, 
                    audio: false
                });
                
                video.srcObject = stream;
                statusDisp.innerText = "Align Red Boxes to Bars";
                isRunning = true;
                requestAnimationFrame(loop);

            } catch(e) {
                alert("Camera Error: " + e.message);
            }
        });

        function loop(time) {
            requestAnimationFrame(loop);
            if (!isRunning) return;

            if(time - lastTime >= 1000) {
                fpsDisp.innerText = `FPS: ${frames}`;
                frames = 0;
                lastTime = time;
            }
            frames++;

            if (video.readyState !== video.HAVE_ENOUGH_DATA) return;

            if (proc.width !== video.videoWidth) {
                proc.width = video.videoWidth;
                proc.height = video.videoHeight;
                overlay.width = video.videoWidth;
                overlay.height = video.videoHeight;
            }

            ctx.drawImage(video, 0, 0);

            const w = proc.width;
            const h = proc.height;
            const zoneW = w / 7; 
            const startX = zoneW; 
            const sampleY = h / 2;
            const sampleH = h / 4; 

            overlayCtx.clearRect(0, 0, w, h);
            overlayCtx.strokeStyle = "red";
            overlayCtx.lineWidth = 3;

            for(let i=0; i<5; i++) {
                const x = startX + (i * zoneW);
                const y = sampleY - (sampleH/2);
                
                overlayCtx.strokeRect(x, y, zoneW*0.8, sampleH);

                const imgData = ctx.getImageData(x + (zoneW*0.4), y, 2, sampleH).data;
                
                let total = 0;
                for(let p=0; p<imgData.length; p+=4) {
                    total += imgData[p] + imgData[p+1] + imgData[p+2];
                }
                
                // Normalization
                const brightness = total / ((imgData.length/4) * 765);

                // --- MIXING ADJUSTMENT ---
                // Tonal channels (0-2) get FULL volume (2.0)
                // Noise channels (3-4) get HALF volume (0.5) so they don't drown out the tones
                const volumeMix = i < 3 ? 2.0 : 0.5;
                
                // Faster reaction time (0.05s) for snappy response
                synths[i].gain.gain.setTargetAtTime(brightness * volumeMix, audioCtx.currentTime, 0.05);
            }
        }
    </script>


</body>
</html>


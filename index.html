<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>5-Channel Receiver</title>
    <style>
        body { margin: 0; background: #000; color: #0f0; font-family: monospace; overflow: hidden; }
        video { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
        
        /* Overlay Canvas for drawing the alignment boxes */
        #overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; }
        
        #ui { position: absolute; top: 10px; left: 10px; z-index: 10; background: rgba(0,0,0,0.5); padding: 5px; pointer-events: none; }
        #startBtn { position: absolute; bottom: 50px; left: 50%; transform: translateX(-50%); padding: 20px 40px; font-size: 20px; font-weight: bold; background: #0f0; border: none; cursor: pointer; z-index: 20; }
    </style>
</head>
<body>

    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>
    
    <div id="ui">
        <div id="fps">FPS: 0</div>
        <div id="status">Waiting...</div>
    </div>

    <button id="startBtn">ACTIVATE 5-CH SYSTEM</button>

    <canvas id="proc" style="display:none;"></canvas>

    <script>
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const overlayCtx = overlay.getContext('2d');
        const proc = document.getElementById('proc');
        const ctx = proc.getContext('2d', { willReadFrequently: true });
        const fpsDisp = document.getElementById('fps');
        
        let audioCtx;
        // Pentatonic Scale (Harmonious robot sounds)
        // frequencies: 55(A1), 69(C#2), 82(E2), 110(A2), 138(C#3)
        const freqs = [55, 69, 82, 110, 138]; 
        const synths = [];

        let lastTime = 0;
        let frames = 0;

        document.getElementById('startBtn').addEventListener('click', async () => {
            document.getElementById('startBtn').style.display = 'none';
            document.getElementById('status').innerText = "Running...";

            // Init Audio
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            for(let i=0; i<5; i++) {
                const osc = audioCtx.createOscillator();
                const gain = audioCtx.createGain();
                osc.type = 'triangle'; // Softer tone
                osc.frequency.value = freqs[i];
                gain.gain.value = 0;
                osc.connect(gain);
                gain.connect(audioCtx.destination);
                osc.start();
                synths.push({osc, gain});
            }

            // Init Camera
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: 'environment', width: { ideal: 1280 }, frameRate: { ideal: 60 } }, audio: false
                });
                video.srcObject = stream;
                
                // Start Loop
                requestAnimationFrame(loop);
            } catch(e) {
                alert("Camera Error: " + e.message);
            }
        });

        function loop(time) {
            requestAnimationFrame(loop);

            // FPS Calculation
            if(time - lastTime >= 1000) {
                fpsDisp.innerText = `FPS: ${frames}`;
                fpsDisp.style.color = frames < 50 ? 'red' : '#0f0';
                frames = 0;
                lastTime = time;
            }
            frames++;

            if (video.readyState !== video.HAVE_ENOUGH_DATA) return;

            // Resize canvases to match video stream
            if (proc.width !== video.videoWidth) {
                proc.width = video.videoWidth;
                proc.height = video.videoHeight;
                overlay.width = video.videoWidth;
                overlay.height = video.videoHeight;
            }

            // 1. Draw Video to Processing Canvas
            ctx.drawImage(video, 0, 0);

            // 2. Define the 5 Zones (Horizontal spread)
            const w = proc.width;
            const h = proc.height;
            const zoneW = w / 7; // Divide screen roughly into slots
            const startX = zoneW; // Start slightly in
            const sampleY = h / 2;
            const sampleH = h / 4;

            // Clear Overlay
            overlayCtx.clearRect(0, 0, w, h);
            overlayCtx.strokeStyle = "red";
            overlayCtx.lineWidth = 4;

            // 3. Process Each Zone
            for(let i=0; i<5; i++) {
                // Calculate position for this zone
                const x = startX + (i * zoneW);
                const y = sampleY - (sampleH/2);
                
                // Draw Debug Box on Overlay
                overlayCtx.strokeRect(x, y, zoneW*0.8, sampleH);

                // Read Pixel Data (Sample vertical strip inside the box)
                // We take a smaller sample from the center of the box to be safe
                const imgData = ctx.getImageData(x + (zoneW*0.4), y, 2, sampleH).data;
                
                let total = 0;
                for(let p=0; p<imgData.length; p+=4) {
                    total += imgData[p] + imgData[p+1] + imgData[p+2];
                }
                
                // Normalize 0.0 - 1.0
                // Max possible = 255 * 3 * numPixels
                const brightness = total / ((imgData.length/4) * 765);

                // Audio Mapping
                // Use "Slew" (0.1s) to smooth out the 60hz flicker
                synths[i].gain.gain.setTargetAtTime(brightness * 2.0, audioCtx.currentTime, 0.1);
            }
        }
    </script>
</body>
</html>


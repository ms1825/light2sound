<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>3-Channel Spatial Receiver</title>
    <style>
        body { margin: 0; background: #000; color: #fff; font-family: monospace; text-align: center; }
        video { width: 100%; height: 60vh; object-fit: cover; }
        
        /* The Alignment Guide */
        .guide-container { 
            position: absolute; top: 30vh; left: 50%; transform: translateX(-50%); 
            display: flex; gap: 5px; opacity: 0.7; pointer-events: none;
        }
        .guide-box { width: 30px; height: 80px; border: 2px solid white; }
        
        #status { margin-top: 10px; color: #aaa; }
        button { font-size: 18px; padding: 15px; margin-top: 10px; background: #0f0; border: none; }
    </style>
</head>
<body>

    <div class="guide-container">
        <div class="guide-box" style="border-color: red;"></div>
        <div class="guide-box" style="border-color: green;"></div>
        <div class="guide-box" style="border-color: cyan;"></div>
    </div>
    
    <video id="video" autoplay playsinline muted></video>
    <div id="status">Align the 3 bars inside the 3 boxes</div>
    <button id="startBtn">START RECEIVER</button>
    <canvas id="canvas" style="display:none;"></canvas>

    <script>
        const startBtn = document.getElementById('startBtn');
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d', { willReadFrequently: true });
        
        let audioCtx;
        const synths = {
            bass: { osc: null, gain: null, freq: 65 },  
            mid:  { osc: null, gain: null, freq: 130 }, 
            high: { osc: null, gain: null, freq: 195 }  
        };

        startBtn.addEventListener('click', async () => {
            startBtn.style.display = 'none';
            audioCtx = new (window.AudioContext || window.webkitAudioContext)();

            Object.keys(synths).forEach(key => {
                const s = synths[key];
                s.osc = audioCtx.createOscillator();
                s.gain = audioCtx.createGain();
                s.osc.type = 'triangle'; 
                s.osc.frequency.value = s.freq;
                s.gain.gain.value = 0;
                s.osc.connect(s.gain);
                s.gain.connect(audioCtx.destination);
                s.osc.start();
            });

            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment', width: { ideal: 1280 }, frameRate: { ideal: 60 } }, audio: false
            });
            video.srcObject = stream;
            processFrame();
        });

        function processFrame() {
            requestAnimationFrame(processFrame);
            if (video.readyState !== video.HAVE_ENOUGH_DATA) return;

            if (canvas.width !== video.videoWidth) {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
            }
            ctx.drawImage(video, 0, 0);

            // We need to sample 3 separate areas
            const w = canvas.width;
            const h = canvas.height;
            const boxW = 20; // Sample size
            
            // Calculate center points for Left, Middle, Right (Assuming guide is centered)
            // You might need to adjust 'offset' depending on how far apart your PC bars are physically
            // Relative to the camera view, we assume they are clustered in the center
            const spacing = w * 0.08; // Distance between sample points (Adjust this if bars are too far/close)
            
            const leftX  = (w/2) - spacing;
            const midX   = (w/2);
            const rightX = (w/2) + spacing;
            const sampleY = h/2;

            function getBrightness(x, y) {
                const img = ctx.getImageData(x - 10, y - 40, 20, 80).data; // Sample a vertical strip
                let sum = 0;
                // Sample only the Green channel for simplicity (since it carries brightness well for all colors in YUV)
                // OR sample RGB specific channels for maximum precision
                for(let i=0; i<img.length; i+=4) {
                    sum += img[i] + img[i+1] + img[i+2];
                }
                return (sum / (img.length/4)) / (255*3);
            }

            // Get brightness of the 3 zones
            const bVal = getBrightness(leftX, sampleY);
            const mVal = getBrightness(midX, sampleY);
            const hVal = getBrightness(rightX, sampleY);

            // Audio Mapping
            const now = audioCtx.currentTime;
            synths.bass.gain.gain.setTargetAtTime(bVal * 2, now, 0.05); 
            synths.mid.gain.gain.setTargetAtTime(mVal * 1.5, now, 0.05);
            synths.high.gain.gain.setTargetAtTime(hVal * 1.0, now, 0.05);
        }
    </script>
</body>
</html>


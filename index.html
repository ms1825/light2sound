<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Optical Vocoder Receiver v2</title>
    <style>
        body { 
            margin: 0; 
            background: #000; 
            color: #0f0; 
            font-family: 'Courier New', monospace; 
            overflow: hidden; 
        }
        video { 
            position: absolute; 
            top: 0; left: 0; width: 100%; height: 100%; 
            object-fit: cover; 
            filter: contrast(1.2) brightness(1.1); 
        }
        #overlay { 
            position: absolute; top: 0; left: 0; width: 100%; height: 100%; 
            pointer-events: none; 
        }
        
        /* UI Panel */
        #ui { 
            position: absolute; 
            top: 10px; left: 10px; 
            z-index: 10; 
            background: rgba(0,0,0,0.7); 
            padding: 10px; 
            border: 1px solid #0f0;
            border-radius: 5px;
        }
        
        #fps { font-weight: bold; font-size: 14px; margin-bottom: 5px; }
        #status { font-size: 11px; color: #aaa; margin-bottom: 10px; }

        /* The New Dropdown Selector */
        select {
            background: #222;
            color: #fff;
            border: 1px solid #0f0;
            padding: 5px;
            font-family: monospace;
            font-size: 14px;
            width: 100%;
        }

        #startBtn { 
            position: absolute; bottom: 50px; left: 50%; transform: translateX(-50%); 
            padding: 20px 40px; font-size: 20px; font-weight: bold; 
            background: #0f0; color: #000; border: none; cursor: pointer; 
            z-index: 20; box-shadow: 0 0 15px #0f0; border-radius: 5px;
        }
    </style>
</head>
<body>

    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay"></canvas>
    
    <div id="ui">
        <div id="fps">FPS: 0</div>
        <div id="status">Ready...</div>
        
        <label style="font-size:12px;">VOICE TYPE:</label><br>
        <select id="waveSelect">
            <option value="square">Harmonica (Square)</option>
            <option value="sawtooth">Robot Voice (Saw)</option>
            <option value="sine">Sci-Fi (Sine)</option>
            <option value="triangle">Flute (Triangle)</option>
        </select>
    </div>

    <button id="startBtn">START RECEIVER</button>
    <canvas id="proc" style="display:none;"></canvas>

    <script>
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const overlayCtx = overlay.getContext('2d');
        const proc = document.getElementById('proc');
        const ctx = proc.getContext('2d', { willReadFrequently: true });
        const fpsDisp = document.getElementById('fps');
        const statusDisp = document.getElementById('status');
        const waveSelect = document.getElementById('waveSelect');
        
        let audioCtx;
        const synths = [];
        let isRunning = false;

        // A Major Chord (Phone friendly frequencies)
        const tonalFreqs = [440, 554, 659]; 

        let lastTime = 0;
        let frames = 0;

        // --- REAL TIME WAVEFORM CHANGER ---
        waveSelect.addEventListener('change', (e) => {
            const newType = e.target.value;
            if(!audioCtx) return;
            
            // Only update channels 0, 1, 2 (The Tonal Oscillators)
            // Channels 3 & 4 are Noise Buffers and don't have a 'type'
            for(let i=0; i<3; i++) {
                if(synths[i] && synths[i].node) {
                    synths[i].node.type = newType;
                }
            }
            statusDisp.innerText = `Mode: ${newType.toUpperCase()}`;
        });

        function createNoiseBuffer(ctx) {
            const bufferSize = ctx.sampleRate * 2; 
            const buffer = ctx.createBuffer(1, bufferSize, ctx.sampleRate);
            const data = buffer.getChannelData(0);
            for (let i = 0; i < bufferSize; i++) {
                data[i] = Math.random() * 2 - 1;
            }
            return buffer;
        }

        document.getElementById('startBtn').addEventListener('click', async () => {
            document.getElementById('startBtn').style.display = 'none';
            statusDisp.innerText = "Initializing...";

            audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const noiseBuffer = createNoiseBuffer(audioCtx);

            // Get initial wave type from dropdown
            const startType = waveSelect.value;

            for(let i=0; i<5; i++) {
                const gain = audioCtx.createGain();
                gain.gain.value = 0;
                gain.connect(audioCtx.destination);
                let node;

                if (i < 3) {
                    // Tonal Channels
                    node = audioCtx.createOscillator();
                    node.type = startType; 
                    node.frequency.value = tonalFreqs[i];
                    node.start();
                } else {
                    // Noise Channels
                    node = audioCtx.createBufferSource();
                    node.buffer = noiseBuffer;
                    node.loop = true;
                    node.playbackRate.value = i === 3 ? 0.5 : 1.0; 
                    node.start();
                }

                node.connect(gain);
                synths.push({ node, gain });
            }

            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        facingMode: 'environment', 
                        width: { ideal: 1280 }, 
                        frameRate: { ideal: 60, min: 30 } 
                    }, 
                    audio: false
                });
                
                // Try to lock camera settings
                const track = stream.getVideoTracks()[0];
                const capabilities = track.getCapabilities();
                if (capabilities.focusMode) try { await track.applyConstraints({ advanced: [{ focusMode: "continuous" }] }); } catch(e){}
                if (capabilities.exposureMode) try { await track.applyConstraints({ advanced: [{ exposureMode: "continuous" }] }); } catch(e){}

                video.srcObject = stream;
                statusDisp.innerText = "Align Red Boxes";
                isRunning = true;
                requestAnimationFrame(loop);

            } catch(e) {
                alert("Camera Error: " + e.message);
            }
        });

        function loop(time) {
            requestAnimationFrame(loop);
            if (!isRunning) return;

            if(time - lastTime >= 1000) {
                fpsDisp.innerText = `FPS: ${frames}`;
                fpsDisp.style.color = frames < 50 ? 'red' : '#0f0';
                frames = 0;
                lastTime = time;
            }
            frames++;

            if (video.readyState !== video.HAVE_ENOUGH_DATA) return;

            if (proc.width !== video.videoWidth) {
                proc.width = video.videoWidth;
                proc.height = video.videoHeight;
                overlay.width = video.videoWidth;
                overlay.height = video.videoHeight;
            }

            ctx.drawImage(video, 0, 0);

            const w = proc.width;
            const h = proc.height;
            const zoneW = w / 7; 
            const startX = zoneW; 
            const sampleY = h / 2;
            const sampleH = h / 4; 

            overlayCtx.clearRect(0, 0, w, h);
            overlayCtx.strokeStyle = "red";
            overlayCtx.lineWidth = 3;

            for(let i=0; i<5; i++) {
                const x = startX + (i * zoneW);
                const y = sampleY - (sampleH/2);
                
                overlayCtx.strokeRect(x, y, zoneW*0.8, sampleH);

                const imgData = ctx.getImageData(x + (zoneW*0.4), y, 2, sampleH).data;
                
                let total = 0;
                for(let p=0; p<imgData.length; p+=4) {
                    total += imgData[p] + imgData[p+1] + imgData[p+2];
                }
                
                const brightness = total / ((imgData.length/4) * 765);

                // Mix Volumes: Tones get full volume, Noise gets half
                const volumeMix = i < 3 ? 2.0 : 0.5;
                const smoothTime = i < 3 ? 0.08 : 0.05;

                synths[i].gain.gain.setTargetAtTime(brightness * volumeMix, audioCtx.currentTime, smoothTime);
            }
        }
    </script>
</body>
</html>


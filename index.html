<!DOCTYPE html>
<html>
<head>
    <script src="https://cdn.jsdelivr.net/npm/jsqr@1.4.0/dist/jsQR.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body { background: #111; color: #fff; font-family: monospace; text-align: center; margin: 0; }
        canvas { width: 100%; height: 50vh; background: #000; }
        #status { padding: 20px; font-size: 16px; color: #0f0; border-top: 1px solid #333; }
        #log { font-size: 12px; color: #888; text-align: left; padding: 10px; height: 150px; overflow-y: scroll; }
    </style>
</head>
<body>
    <canvas id="canvas"></canvas>
    <div id="status">Waiting for Stream...</div>
    <div id="log"></div>

    <script>
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        const status = document.getElementById("status");
        const logDiv = document.getElementById("log");

        // Audio Engine
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        let nextPlayTime = 0;

        // Buffers
        let currentChunkID = -1;
        let receivedParts = {}; // Stores parts of the current chunk
        let processedChunks = new Set(); // History to avoid re-playing

        function log(msg) {
            logDiv.innerHTML = `> ${msg}<br>` + logDiv.innerHTML;
        }

        // Camera Loop
        navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } }).then((stream) => {
            const video = document.createElement("video");
            video.srcObject = stream;
            video.setAttribute("playsinline", true);
            video.play();
            requestAnimationFrame(() => tick(video));
        });

        function tick(video) {
            if (video.readyState === video.HAVE_ENOUGH_DATA) {
                canvas.height = video.videoHeight;
                canvas.width = video.videoWidth;
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                
                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                const code = jsQR(imageData.data, imageData.width, imageData.height, { inversionAttempts: "dontInvert" });

                if (code) {
                    parsePacket(code.data);
                    // Draw Green Box
                    ctx.strokeStyle = "#00FF00";
                    ctx.lineWidth = 4;
                    ctx.strokeRect(code.location.topLeftCorner.x, code.location.topLeftCorner.y, 
                                 code.location.bottomRightCorner.x - code.location.topLeftCorner.x,
                                 code.location.bottomRightCorner.y - code.location.topLeftCorner.y);
                }
            }
            requestAnimationFrame(() => tick(video));
        }

        function parsePacket(data) {
            // Protocol: ID-Part/Total|Data
            try {
                const [header, payload] = data.split('|');
                const [idStr, countStr] = header.split('-');
                const [partStr, totalStr] = countStr.split('/');

                const id = parseInt(idStr);
                const part = parseInt(partStr);
                const total = parseInt(totalStr);

                // Ignore if we already played this chunk
                if (processedChunks.has(id)) return;

                // If this is a new chunk, clear old buffer
                if (id > currentChunkID) {
                    currentChunkID = id;
                    receivedParts = {}; 
                    status.innerText = `Receiving Chunk ${id}...`;
                }

                // Store Part
                if (!receivedParts[part]) {
                    receivedParts[part] = payload;
                    
                    // Check if we have ALL parts
                    if (Object.keys(receivedParts).length === total) {
                        finalizeChunk(id, total);
                    }
                }
            } catch (e) {
                // Garbage data or scan error
            }
        }

        async function finalizeChunk(id, total) {
            processedChunks.add(id);
            status.innerText = `Decoding Chunk ${id}...`;
            log(`Chunk ${id} Complete (${total} packets). Decoding...`);

            // 1. Reassemble Base64
            let fullBase64 = "";
            for (let i = 1; i <= total; i++) {
                fullBase64 += receivedParts[i];
            }

            // 2. Convert to ArrayBuffer
            const binaryString = window.atob(fullBase64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }

            // 3. Decode Opus Audio
            try {
                const audioBuffer = await audioCtx.decodeAudioData(bytes.buffer);
                scheduleAudio(audioBuffer);
            } catch (e) {
                log("Decode Error: " + e.message);
            }
        }

        function scheduleAudio(buffer) {
            const source = audioCtx.createBufferSource();
            source.buffer = buffer;
            source.connect(audioCtx.destination);

            // "Gapless" Logic:
            // If the previous chunk is still playing, schedule this one to start right after.
            // If nothing is playing, start immediately.
            const now = audioCtx.currentTime;
            if (nextPlayTime < now) {
                nextPlayTime = now + 0.1; // Small buffer for instant start
            }

            source.start(nextPlayTime);
            nextPlayTime += buffer.duration;
            
            status.innerText = "Playing Stream...";
            status.style.color = "#00FF00";
        }
    </script>
</body>
</html>

